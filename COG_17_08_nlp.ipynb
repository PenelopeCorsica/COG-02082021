{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "COG_17_08_nlp.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPUxdX7h9QPmIgh+1vAcaGz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/a-forty-two/COG-02082021/blob/main/COG_17_08_nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60p8XExqHSUK"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JV77DGMEHYfJ",
        "outputId": "22759f93-a6f2-4177-b9f5-17fccb0eaea4"
      },
      "source": [
        "imdb = keras.datasets.imdb\n",
        "(xtrain,ytrain),(xtest,ytest) = imdb.load_data(num_words=10000)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVZuKnEoHkLT",
        "outputId": "dd58936e-f3cd-4464-b095-2cab046ef438"
      },
      "source": [
        "xtrain.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gu_HuMmnHnzH",
        "outputId": "9c5c647c-edf5-4fb5-d60e-b6f957b3074a"
      },
      "source": [
        "xtest.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUNR8mB-Hqpb",
        "outputId": "a7d704d2-0233-428a-8e0f-5ac4c2a14d63"
      },
      "source": [
        "print(xtrain[0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyjE2OTDHuW6",
        "outputId": "9f36cfcf-7039-4187-ee42-c95eebdc6a40"
      },
      "source": [
        "ytrain[0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRfK_lqxH2O6",
        "outputId": "e1600b7a-32d3-4d61-c367-f173dac8915f"
      },
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame(ytrain).value_counts()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    12500\n",
              "0    12500\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8IzMBj0H5Gf",
        "outputId": "c3f5f0b3-a7d9-4f24-832d-cf513538eca5"
      },
      "source": [
        "print(dir(imdb))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '_sys', 'get_word_index', 'load_data']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTuSeQrpIMwr",
        "outputId": "44e021fe-d5dd-4dac-a439-240ef88da887"
      },
      "source": [
        "wordindex = imdb.get_word_index()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1kVAGBGISxY",
        "outputId": "2cca6383-f6bc-4347-af79-c67fea721d2c"
      },
      "source": [
        "wordindex['hello']"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4822"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNb0AEVaIU4q"
      },
      "source": [
        "revwordindex = { v:k for k,v in wordindex.items()}\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "SDKE7mBXIwCC",
        "outputId": "570f9fc2-bf87-4604-a29b-b533abb34c15"
      },
      "source": [
        "revwordindex[4822]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'hello'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WVhGqIBIzLg"
      },
      "source": [
        "def decoder(moviereview):\n",
        "  return \" \".join([revwordindex[word] for word in moviereview])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "CHSZhsjRJMxR",
        "outputId": "14b25ec8-8b44-4025-e9ff-dac6ced898b1"
      },
      "source": [
        "decoder(xtrain[0])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"the as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room and it so heart shows to years of every never going and help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but and to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other and in of seen over landed for anyone of and br show's to whether from than out themselves history he name half some br of and odd was two most of mean for 1 any an boat she he should is thought frog but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with heartfelt film want an\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgsFvdtVJQf2"
      },
      "source": [
        "# first few vectors are reserved for special use cases:\n",
        "# <PAD> 0 values which shouldn't participate in ML\n",
        "# <START> 1 indicates start of an input\n",
        "# <UNKNOWN> 2 -> UNKNOWN vectors\n",
        "# we have taken only 10000 words-> any word_vector > 10000-> UNKNOWN\n",
        "# <UNUSED> 3 -> UNUSED \n",
        "corrected_wordindex = { k:v+3 for k,v in wordindex.items()}\n",
        "corrected_wordindex[\"<PAD>\"] = 0\n",
        "corrected_wordindex[\"<START>\"] = 1\n",
        "corrected_wordindex[\"<UNKNOWN>\"] = 2\n",
        "corrected_wordindex[\"<UNUSED>\"] = 3"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "eI3Ty7xDJr4R",
        "outputId": "06b3d123-7c7b-4cb3-96e5-fcece3333c5d"
      },
      "source": [
        "# we already know some indexes need fixing !\n",
        "print(revwordindex[2])\n",
        "print(revwordindex[1])\n",
        "revwordindex[0]\n",
        "# and and the are present where UNKNOWN and START should have been!"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "and\n",
            "the\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-5d040ec18065>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrevwordindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrevwordindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mrevwordindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# and and the are present where UNKNOWN and START should have been!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6XwGzhOJ7d9"
      },
      "source": [
        "dictionary = { v:k for k,v in corrected_wordindex.items()}\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3PRZImIZKq9W",
        "outputId": "b37c4ab6-27b9-4585-b8ab-f695e3b6317b"
      },
      "source": [
        "dictionary[42]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'or'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "y32qwflsK_Ad",
        "outputId": "acd1064b-ea27-45de-daab-e8e84aaba344"
      },
      "source": [
        "print(dictionary[2])\n",
        "print(dictionary[1])\n",
        "dictionary[0]"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<UNKNOWN>\n",
            "<START>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<PAD>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coRdNiLaLD5L"
      },
      "source": [
        "def decoder(moviereview):\n",
        "  return \" \".join([dictionary[word] for word in moviereview])"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "sEVbBJUXLfBD",
        "outputId": "a7bd30c1-8b68-496e-baa4-e1fe064103c4"
      },
      "source": [
        "decoder(xtrain[0])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"<START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNKNOWN> is an amazing actor and now the same being director <UNKNOWN> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNKNOWN> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNKNOWN> to the two little boy's that played the <UNKNOWN> of norman and paul they were just brilliant children are often left out of the <UNKNOWN> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "tCR1ACauLgsd",
        "outputId": "0ed4b3cb-cbca-4eab-b150-6789263c0644"
      },
      "source": [
        "decoder(xtrain[10000])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"<START> i think this is one of the weakest of the kenneth branagh <UNKNOWN> works after such great efforts as much <UNKNOWN> about nothing etc i thought this was poor the cast was weaker alicia <UNKNOWN> <UNKNOWN> <UNKNOWN> but my biggest <UNKNOWN> was that they messed with the <UNKNOWN> work and cut out some of the play to put in the musical dance sequences br br you just don't do shakespeare and then mess with the play sorry but that is just wrong i love some cole porter just like the next person but <UNKNOWN> don't mess with the shakespeare skip this and watch <UNKNOWN> books if you want to see a brilliant shakespearean adaptation of the <UNKNOWN>\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ose3uWjzMRYl",
        "outputId": "e27d3464-43db-4387-d4c2-6610b86533c3"
      },
      "source": [
        "for i in range(10):\n",
        "  print(len(xtrain[i]))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "218\n",
            "189\n",
            "141\n",
            "550\n",
            "147\n",
            "43\n",
            "123\n",
            "562\n",
            "233\n",
            "130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huc5q6YEO1HG"
      },
      "source": [
        "# w1v1 + w2v2 + w3v3 + ... w100*0 + w101*0 + w102*0 = 1\n",
        "# w1v1 + w2v2 + w3v3 + ... w100*v100 + w101*v101 + w102*0 =1\n",
        "# w1*this + w2*was + w3*a + ... w100*0 + w101*0 + w102*0 = 1\n",
        "# w1*this + w2*was + w3*a + ... w100*watch + w101*again + w102*0 =1\n",
        "# NLP+CV = PADDING"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qriHijadPxgT"
      },
      "source": [
        "xtrainpadded = keras.preprocessing.sequence.pad_sequences(xtrain,maxlen=256,\n",
        "                                                          padding='post',truncating='post')"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8Xv7-cLQDuN",
        "outputId": "9be283cb-92df-45c2-faf4-86a056466d37"
      },
      "source": [
        "for i in range(10):\n",
        "  print(len(xtrainpadded[i]))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n",
            "256\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXtRGA-bQHbO",
        "outputId": "68632a3f-d375-4926-d288-ac22002989c0"
      },
      "source": [
        "# 7-> larger than 255, 5-> smaller than 255\n",
        "print(decoder(xtrainpadded[5]))\n",
        "print('***')\n",
        "print(decoder(xtrainpadded[3]))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<START> begins better than it ends funny that the russian submarine crew <UNKNOWN> all other actors it's like those scenes where documentary shots br br spoiler part the message <UNKNOWN> was contrary to the whole story it just does not <UNKNOWN> br br <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "***\n",
            "<START> the <UNKNOWN> <UNKNOWN> at storytelling the traditional sort many years after the event i can still see in my <UNKNOWN> eye an elderly lady my friend's mother retelling the battle of <UNKNOWN> she makes the characters come alive her passion is that of an eye witness one to the events on the <UNKNOWN> heath a mile or so from where she lives br br of course it happened many years before she was born but you wouldn't guess from the way she tells it the same story is told in bars the length and <UNKNOWN> of scotland as i discussed it with a friend one night in <UNKNOWN> a local cut in to give his version the discussion continued to closing time br br stories passed down like this become part of our being who doesn't remember the stories our parents told us when we were children they become our invisible world and as we grow older they maybe still serve as inspiration or as an emotional <UNKNOWN> fact and fiction blend with <UNKNOWN> role models warning stories <UNKNOWN> magic and mystery br br my name is <UNKNOWN> like my grandfather and his grandfather before him our protagonist introduces himself to us and also introduces the story that stretches back through generations it produces stories within stories stories that evoke the <UNKNOWN> wonder of scotland its rugged mountains <UNKNOWN> in <UNKNOWN> the stuff of legend yet <UNKNOWN> is <UNKNOWN> in reality this is what gives it its special charm it has a rough beauty and\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoZT7d58QVhU",
        "outputId": "dcda59a8-ca04-4cc5-b13a-0740c76cd4a8"
      },
      "source": [
        "print(xtrainpadded[5])"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[   1  778  128   74   12  630  163   15    4 1766 7982 1051    2   32\n",
            "   85  156   45   40  148  139  121  664  665   10   10 1361  173    4\n",
            "  749    2   16 3804    8    4  226   65   12   43  127   24    2   10\n",
            "   10    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVcNqfmWRKnk"
      },
      "source": [
        "xtestpadded = keras.preprocessing.sequence.pad_sequences(xtest,maxlen=256,\n",
        "                                                          padding='post',truncating='post')"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5AXwz2vRSef"
      },
      "source": [
        "layer1 = keras.layers.Embedding(10000, 16) # 160k weights\n",
        "layer2 = keras.layers.GlobalAveragePooling1D() # 0 weights\n",
        "layer3 = keras.layers.Dense(32, activation=tf.nn.relu) # input*output+output\n",
        "# all neg filtered out\n",
        "layer4 = keras.layers.Dense(64, activation = tf.nn.relu)\n",
        "# all neg filtered out\n",
        "layer5 = keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
        "# scale between 0 to 1\n",
        "# if > 0.5, assume 1, else 0 \n",
        "# if instead, i'd use softmax-> expected output-> [0.88,0.12], [0.01, 0.99]\n",
        "model = keras.models.Sequential([layer1, layer2,layer3,layer4,layer5])"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptJ8BysRe7T9"
      },
      "source": [
        "model.compile(loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.Adam(), metrics=[\"accuracy\"])"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "do9rxsm7fM4b",
        "outputId": "da2f77a8-17dc-430c-9239-536c727d2315"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 16)          160000    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_1 ( (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 32)                544       \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 162,721\n",
            "Trainable params: 162,721\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2R77sM3wfP2u",
        "outputId": "00e89545-db02-451d-b48d-0981895fa815"
      },
      "source": [
        "history = model.fit(xtrainpadded, ytrain, epochs=50)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "782/782 [==============================] - 6s 6ms/step - loss: 0.4184 - accuracy: 0.8070\n",
            "Epoch 2/50\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.2328 - accuracy: 0.9080\n",
            "Epoch 3/50\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.1824 - accuracy: 0.9324\n",
            "Epoch 4/50\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.1515 - accuracy: 0.9448\n",
            "Epoch 5/50\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.1282 - accuracy: 0.9566\n",
            "Epoch 6/50\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.1092 - accuracy: 0.9641\n",
            "Epoch 7/50\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0969 - accuracy: 0.9690\n",
            "Epoch 8/50\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0831 - accuracy: 0.9756\n",
            "Epoch 9/50\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0782 - accuracy: 0.9744\n",
            "Epoch 10/50\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0642 - accuracy: 0.9804\n",
            "Epoch 11/50\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0565 - accuracy: 0.9820\n",
            "Epoch 12/50\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0453 - accuracy: 0.9846\n",
            "Epoch 13/50\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0442 - accuracy: 0.9839\n",
            "Epoch 14/50\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0327 - accuracy: 0.9869\n",
            "Epoch 15/50\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0285 - accuracy: 0.9889\n",
            "Epoch 16/50\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0278 - accuracy: 0.9889\n",
            "Epoch 17/50\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0217 - accuracy: 0.9922\n",
            "Epoch 18/50\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.0239 - accuracy: 0.9908\n",
            "Epoch 19/50\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0248 - accuracy: 0.9907\n",
            "Epoch 20/50\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0165 - accuracy: 0.9941\n",
            "Epoch 21/50\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0124 - accuracy: 0.9956\n",
            "Epoch 22/50\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0177 - accuracy: 0.9929\n",
            "Epoch 23/50\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0183 - accuracy: 0.9933\n",
            "Epoch 24/50\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0159 - accuracy: 0.9942\n",
            "Epoch 25/50\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0155 - accuracy: 0.9944\n",
            "Epoch 26/50\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0115 - accuracy: 0.9962\n",
            "Epoch 27/50\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0107 - accuracy: 0.9962\n",
            "Epoch 28/50\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0191 - accuracy: 0.9930\n",
            "Epoch 29/50\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0119 - accuracy: 0.9956\n",
            "Epoch 30/50\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0058 - accuracy: 0.9979\n",
            "Epoch 31/50\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0139 - accuracy: 0.9952\n",
            "Epoch 32/50\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0099 - accuracy: 0.9961\n",
            "Epoch 33/50\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0091 - accuracy: 0.9968\n",
            "Epoch 34/50\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.0121 - accuracy: 0.9960\n",
            "Epoch 35/50\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0072 - accuracy: 0.9978\n",
            "Epoch 36/50\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0093 - accuracy: 0.9967\n",
            "Epoch 37/50\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0096 - accuracy: 0.9964\n",
            "Epoch 38/50\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.0143 - accuracy: 0.9952\n",
            "Epoch 39/50\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.0056 - accuracy: 0.9978\n",
            "Epoch 40/50\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0067 - accuracy: 0.9976\n",
            "Epoch 41/50\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0080 - accuracy: 0.9972\n",
            "Epoch 42/50\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0078 - accuracy: 0.9971\n",
            "Epoch 43/50\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0065 - accuracy: 0.9980\n",
            "Epoch 44/50\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0054 - accuracy: 0.9981\n",
            "Epoch 45/50\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0076 - accuracy: 0.9976\n",
            "Epoch 46/50\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0090 - accuracy: 0.9970\n",
            "Epoch 47/50\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0077 - accuracy: 0.9976\n",
            "Epoch 48/50\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0052 - accuracy: 0.9980\n",
            "Epoch 49/50\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0093 - accuracy: 0.9968\n",
            "Epoch 50/50\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0048 - accuracy: 0.9984\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWOkM4d0fyBS",
        "outputId": "9740677e-ec8d-4c1c-bd9d-33353e2be1f1"
      },
      "source": [
        "predictions = model.predict(xtestpadded)\n",
        "mloss, macc = model.evaluate(xtestpadded, ytest)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 1s 1ms/step - loss: 1.7583 - accuracy: 0.8255\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Hwor6AJhJNq",
        "outputId": "67666fb8-f9ee-47fa-8d1f-030b3a6d1ed5"
      },
      "source": [
        "mloss, macc"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.7583379745483398, 0.8255199790000916)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRd9M5qdhASz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}